% !TEX root=./whitepaper.tex

\section{Incentive Mechanism}

This section describes the incentive mechanism design of the \projabbrev Storage, which consists of two types of actors: users and miners (a.k.a. storage nodes). Users pay tokens (\token) to create data entries in the log and add data to the network. Miners provide data service and receive tokens (\token) as a reward from the network. The payment from users to miners is mediated by the \project network since the service is sustained by the entire network rather than specific miners.

\projabbrev Storage implements storage service in a "pay once, store forever" manner. Users pay a one-shot storage endowment for each created data entry, which is used to incentivize miners who maintain that data entry.

The storage endowment is maintained per data entry, and a miner is only eligible for storage rewards from data entries he has access to. The total storage reward paid for a data entry is independent of the popularity of that data entry. For instance, a popular data entry stored by many miners will be frequently mined, but the reward is shared among those miners. Conversely, a less popular data entry is rarely mined, so the storage reward accumulates and induces a higher payoff to miners who store this rare data entry.

\subsection{Storage Request Pricing}

The cost of each \projabbrev Storage request is composed of two parts: fee and storage endowment. The fee is paid to host chain miners/validators for invoking the \project contract to process the storage request and add a new data entry into the log, which is priced like other smart contract invocation transactions. The storage endowment part supports the perpetual reward to \projabbrev Storage miners who serve the corresponding data.

Given a data storage request $\sr$ with a specific amount of endowment $\sr_{endowment}$ and size of committed data $\sr_{data\_size}$ (measured in number of \sectorsize sectors), the unit price of $\sr$ is calculated as follows:
\begin{align}
	\sr_{unit\_price} &= \sr_{endowment}/\sr_{data\_size}
\end{align}

This unit price $\sr_{unit\_price}$ must exceed a globally specified lower bound to be added to the log. Otherwise, the request will be pending until the lower bound decreases below $\sr_{unit\_price}$. Users can set a higher unit price $\sr_{unit\_price}$ to motivate more storage nodes to mine on that data entry, leading to better data availability.

\subsection{\proof}

The \project network adopts a \proof (\sproof) mechanism to incentivize miners to store data. By requiring miners to answer randomly produced queries to archived data chunks, the \sproof mechanism establishes the relation between mining proof generation power and data storage. Miners answer the queries repeatedly and compute an output digest for each loaded chunk until a digest satisfies the mining difficulty (i.e., has enough leading zeros). 

The {\sproof} mechanism will stress the miners' disk I/O and reduce their capability in responding to user queries. Therefore, \projabbrev Storage adopts intermittent mining, where a mining epoch starts with a block generation at a specific block height on the host chain and stops when a valid {\sproof} is submitted to the \projabbrev Storage contract.

In a basic design, a \sproof iteration consists of a computing stage and a loading stage. In the computing stage, a miner computes a random recall position (the universal offset in the flow) based on an arbitrary picked random nonce and mining status read from the host chain. In the loading stage, a miner loads the archived data chunks at the given recall position and computes the output digest by hashing the tuple of mining status and the data chunks. If the output digest satisfies the target difficulty, the miner can construct a legitimate \sproof consisting of the chosen random nonce, the loaded data chunk, and the proof of the correctness of the data chunk to the mining contract.

The following sections introduce major considerations for improving fairness in {\sproof} mining and formalize the {\sproof} mining mechanism.

\subsubsection{Fairness for Small Miners}

When the storage size of the \projabbrev Storage network significantly exceeds the storage capacity of a single machine, finding an available recall position becomes time-consuming for a single machine, effectively turning {\sproof} into a proof of work. To make the {\sproof} mining process friendly to small miners with a single machine, the mining range is limited to a threshold of 8 TB. When the size of archived data chunks exceeds 8 TB, a miner must specify a mining range over the data flow sequence in size of 8 TB. Large miners with enough machines to store all the data can mine on different data ranges concurrently.

\subsubsection{Disincentivizing Storage Outsourcing}

To promote the network storing enough replicas of data chunks, \projabbrev Storage limits the reward share of a single miner with a single storage replica. The {\sproof} mechanism seals the data for each miner in different ways, challenges the accessing of sealed data, and prevents mining with data chunks from others. If a miner outsources data storage and queries the archived data chunks in {\sproof} mining, it must seal the answering data to compute the output digest, which incurs a large cost. As reading data from SSDs can reach up to 7 GB/s, the data sealing is a heavy task for {\sproof} mining. As long as the cost imposed by data sealing exceeds the cost of purchasing disks and synchronizing data, miners will prefer to store a replica of data chunks instead of sealing data during {\sproof} mining.

Every 4KB data chunk will be sealed by the miner ID and other context data. Suppose {\sf seal\_seed} is a 32-byte digest of the miner ID and the context data. The seal process is defined in Algorithm~\ref{fig:seal}.

\begin{algorithm}
	\small
	\SetNlSty{}{}{}
	\DontPrintSemicolon
	\SetKw{To}{ to }
	\SetKw{In}{ in }
	\SetKw{Or}{ or }
	\SetKw{And}{ and }
	\SetKw{From}{ from }
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\SetKw{Define}{define}
	\Input{{\sf seal\_seed}, {\sf unsealed\_data} }
	\Output{{\sf sealed\_data}}
	Regard {\sf unsealed\_data} in length of 4 KB as an array of 32-byte elements $\vec{d}$\;
	$h\leftarrow {\sf seal\_seed}$\;
	\For{$i$\From $0$\To $127$} {
		$\vec{d}[i]\leftarrow \vec{d}[i]{\;\tt XOR\;} h$\;
		$h\leftarrow \textrm{Keccak256}(\vec{d}[i])$\;
	}
	Regard $\vec{d}$ as a 4-KB data chunk {\sf sealed\_data}\;
	\caption{Seal 4 KB data chunks}
	\label{fig:seal}
	\vspace{-4mm}
\end{algorithm}

\subsubsection{Disincentivizing Distributed Mining}

As a mining mechanism for incentivizing data storage, a single storage replica should produce similar hashrate for fairness. In {\sproof} mining, the hashrate is bottlenecked by the storage I/O. However, a mining farm can significantly increase its I/O compared to normal miners by storing data chunks with a distributed system with an in-memory filesystem. The mining farm can produce much more hashrate while contributing negligibly to data storage.

\projabbrev Storage prevents this behavior by imposing a large amount of data transfer from the computing stage to the loading stage to encourage miners to complete both stages on the same machine. If the computing and loading stages are separated on different machines, the hashrate is bounded by the network bandwidth, which is usually smaller than the storage I/O bandwidth. In the computing stage, a random scratchpad will be generated coupled with the recall position. It has the same length as the data chunk to be loaded. Before computing the hash of the loaded data chunk, the data chunk should be mixed with the scratchpad by an XOR operation.

There is a dilemma between the read bandwidth and the transaction fee for submitting {\sproof} to the host chain. Loading data chunks from local disks should be more efficient than downloading them via the network. The loading stage should leverage the fast SSD read speeds in sequential access to maximize the data chunk loading bandwidth. Randomly loading 256-KB data chunks reaches 80% read speed of sequential access. However, submitting the data chunk to the host chain incurs high transaction fees. Reducing the size of the data chunk can mitigate this issue but will impair the read speed.

{\sproof} mechanism adopts "batched data loading" to resolve this dilemma. In each iteration, a miner loads a 256-KB data chunk from storage, divides it into 4-KB data chunks, and computes the hash for each 4-KB data chunk individually. If one of the 64 outputs matches the target quality, the miner finds a valid answer. Only the 4-KB data chunk contributing to this answer is required to be submitted to the host chain.

\subsubsection{Formal Definition for \sproof Mechanism}

The mining process consists of the following steps:
\begin{enumerate}
	\item Register the $\sf miner\_id$ on the mining contract.
	\item For each mining epoch,
	\begin{enumerate}
		\item Compute the starting mining status $\sf mining\_status$ using the block hash of the first block in this epoch.
		\item Perform a loop to find valid \sproof in an epoch,
		\begin{enumerate}
			\item In the computing stage,
			\begin{enumerate}
				\item Sample a random $\sf nonce$.
				\item Compute the recall position $\sf recall\_pos$ by hashing $\sf miner\_id$, $\sf nonce$, and $\sf mining\_status$.
				\item Generate the scratchpad {\sf scratchpad} by hashing the recall position.
			\end{enumerate}
			\item In the loading stage,
			\begin{enumerate}
				\item Load 256-KB data chunks from $\sf recall\_pos$.
				\item Divide the 256-KB data chunks into 64 4-KB chunks.
				\item For each 4-KB chunk,
				\begin{enumerate}
					\item Seal the 4-KB data chunk with {\sf seal\_seed}.
					\item Mix the 4-KB data chunk with the scratchpad by XORing.
					\item Hash the mixed data chunk.
					\item Check whether the hash output meets the target difficulty.
				\end{enumerate}
				\item If a 4-KB data chunk meets the target difficulty, submit the corresponding \sproof to the mining contract.
			\end{enumerate}
		\end{enumerate}
	\end{enumerate}
\end{enumerate}

The above steps ensure that the \sproof mechanism achieves the desired incentive for miners to store data and maintains fairness across different sizes of mining setups.
